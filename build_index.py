import os
import time
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OllamaEmbeddings

INDEX_PATH = "faiss_index"

print("ğŸš€ Starting Mahabharata Index Builder...\n")

# Step 1: Load PDF
print("ğŸ“„ Loading PDF...")
loader = PyPDFLoader("mahabharata.pdf")
docs = loader.load()

print(f"âœ… Total Pages in PDF: {len(docs)}")

# ğŸ”¥ Limit pages for first run (change later if needed)
LIMIT_PAGES = 400
docs = docs[:LIMIT_PAGES]

print(f"âš¡ Using first {LIMIT_PAGES} pages for indexing\n")

# Step 2: Split Text
print("âœ‚ Splitting text into chunks...")
splitter = RecursiveCharacterTextSplitter(
    chunk_size=2000,
    chunk_overlap=200
)

split_docs = splitter.split_documents(docs)

print(f"âœ… Total Chunks Created: {len(split_docs)}\n")

# Step 3: Create Embeddings
print("ğŸ”¢ Generating embeddings using Ollama (nomic-embed-text)...")
start_time = time.time()

embeddings = OllamaEmbeddings(model="nomic-embed-text")

vectorstore = FAISS.from_documents(split_docs, embeddings)

end_time = time.time()
print(f"â± Embedding Time: {round(end_time - start_time, 2)} seconds\n")

# Step 4: Save Index
print("ğŸ’¾ Saving FAISS index locally...")
vectorstore.save_local(INDEX_PATH)

print("\nâœ… FAISS index created successfully!")
print("ğŸ“ Index folder created:", INDEX_PATH)
print("ğŸ‰ You can now run: streamlit run app.py")